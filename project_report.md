Here is the problem statement report for your game, formatted in Markdown.

---

# Project Problem Statement: Prompt Engineering Workshop Game

- **Project:** Prompt Engineering Workshop Game
- **Team:** FTECH (Qui Huynh, Hung Do, Bao Ho, Tan Nguyen)
- **Date:** October 20, 2025

---

## 1. The Problem

The effective use of Large Language Models (LLMs) hinges on a skill known as "prompt engineering," but learning this skill presents a significant challenge.

Current educational resources, such as technical documentation and text-based tutorials, are often:

- **Abstract and Intimidating:** Concepts like "persona," "context," and "output formatting" are difficult for beginners to grasp without practical, hands-on examples.
- **Lacking Interactivity:** Static content doesn't allow learners to experiment safely or receive immediate, instructive feedback. It's hard to understand _why_ one prompt is better than another.
- **Disconnected from Consequences:** Learners don't get a feel for the "cost" (e.g., tokens) or "stability" of their prompts. A poorly formed, "vague" prompt can lead to unpredictable, costly, or incorrect results, which is a key gap in digital literacy.

This creates a barrier for students and professionals who need to leverage AI tools effectively and safely.

## 2. Target Audience

- **Primary:** Students (in Vietnam and Australia, as per the project's focus) who are new to AI and digital literacy concepts.
- **Secondary:** Anyone (developers, writers, marketers, general users) seeking to improve their interaction with AI tools in a practical, engaging way.

## 3. Proposed Solution: "Prompt Engineering Workshop Game"

Our solution is **Prompt Engineering Workshop Game**, a single-page React game that demystifies prompt engineering by turning it into a tangible, interactive "card-Engineering Workshop Gameing" experience.

Instead of reading a tutorial, users _play_ with the core components of a prompt.

- **Core Metaphor:** Players are "alchemists" who combine "ingredient" cards (like **Task**, **Persona**, **Context**, and **Format**) on a "workbench" to Engineering Workshop Game a prompt.
- **Instant Feedback:** Upon "Engineering Workshop Gameing," the game provides immediate results, showing:
  - **Success or Failure:** Did the prompt meet the level's requirements?
  - **Cost:** A simulation of input/output token costs.
  - **Stability:** "Vague" cards introduce unpredictable results, teaching users what to avoid.
  - **Education:** Clear, actionable tips explain _why_ the prompt succeeded or failed.

## 4. Key Objectives

This solution directly addresses the problem by:

1.  **Making the Abstract Concrete:** The card metaphor transforms abstract concepts into physical, movable objects that players can combine and experiment with.
2.  **Providing a Safe Sandbox:** Users can fail and learn without real-world costs or consequences, encouraging experimentation.
3.  **Visualizing Cause and Effect:** Players instantly see how adding a **Persona** card changes the outcome, or how a **Vague** card destabilizes the result.
4.  **Improving Digital Literacy:** The game directly teaches users how to create clear, specific, and structured instructions for AI, a critical skill for navigating digital information and avoiding misinformation.
